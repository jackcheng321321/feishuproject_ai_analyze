#!/usr/bin/env python3
"""
Webhookå¼‚æ­¥å¤„ç†å™¨
æ•´åˆæ•°æ®è§£æã€æ–‡ä»¶è·å–ã€AIåˆ†æã€ç»“æœå›å†™çš„å®Œæ•´æµç¨‹
"""

import asyncio
import json
import time
import uuid
from typing import Dict, Any, Optional
from datetime import datetime
import logging

from app.core.database import SessionLocal
from app.models.webhook import Webhook
from app.models.analysis_task import AnalysisTask
from app.models.task_execution_simple import TaskExecution, ExecutionStatus
from app.models.ai_model import AIModel
from app.models.storage_credential import StorageCredential
from app.services.data_parser import webhook_data_parser
from app.services.file_service import FileService, file_service
from app.services.ai_service import AIService, ai_service
from app.services.feishu_writer import FeishuWriteService

logger = logging.getLogger(__name__)


def _get_provider_from_model_type(model_type):
    """æ ¹æ®æ¨¡å‹ç±»å‹è·å–æä¾›å•†åç§°"""
    from app.models.ai_model import ModelType
    
    type_mapping = {
        ModelType.GEMINI: "google",
        ModelType.OPENAI_COMPATIBLE: "openai",
        ModelType.CLAUDE: "anthropic",
        ModelType.OTHER: "openai"  # é»˜è®¤ä½¿ç”¨OpenAIæ ¼å¼
    }
    
    return type_mapping.get(model_type, "openai")


class WebhookProcessorError(Exception):
    """Webhookå¤„ç†å™¨å¼‚å¸¸"""
    pass


class WebhookTaskProcessor:
    """Webhookä»»åŠ¡å¤„ç†å™¨"""
    
    def __init__(self):
        self.db = None
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.db = SessionLocal()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.db:
            self.db.close()
    
    async def process_webhook_task(
        self,
        webhook_id: int,
        payload_data: Dict[str, Any],
        execution_id: str,
        client_ip: str,
        user_agent: str
    ) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªWebhookä»»åŠ¡çš„å®Œæ•´æµç¨‹

        Args:
            webhook_id: Webhookæ•°æ®åº“ID
            payload_data: ä»webhookæ¥æ”¶çš„åŸå§‹æ•°æ®
            execution_id: æ‰§è¡ŒID
            client_ip: å®¢æˆ·ç«¯IP
            user_agent: ç”¨æˆ·ä»£ç†

        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = time.time()
        execution_log = []
        result = {
            "success": False,
            "execution_id": execution_id,
            "webhook_id": webhook_id,
            "start_time": datetime.utcnow().isoformat(),
            "steps": [],
            "error": None
        }

        task_execution = None

        try:
            # 1. è·å–Webhookå’Œå…³è”çš„åˆ†æä»»åŠ¡
            print(f"\nğŸ“‹ [DEBUG] æ­¥éª¤1: è·å–Webhookå’Œå…³è”ä»»åŠ¡")
            logger.info(f"å¼€å§‹å¤„ç†Webhookä»»åŠ¡ {execution_id}")
            execution_log.append("å¼€å§‹å¤„ç†Webhookä»»åŠ¡")
            
            webhook = self.db.query(Webhook).filter(Webhook.id == webhook_id).first()
            if not webhook:
                error_msg = f"Webhookä¸å­˜åœ¨: {webhook_id}"
                print(f"âŒ [DEBUG] {error_msg}")
                raise WebhookProcessorError(error_msg)
            
            print(f"âœ… [DEBUG] æ‰¾åˆ°Webhook: {webhook.name} (ID: {webhook.id})")
            
            # è·å–å…³è”çš„åˆ†æä»»åŠ¡ - ä¼˜åŒ–ï¼šç¡®ä¿ä¸€å¯¹ä¸€å…³ç³»ï¼Œé¿å…å¤šä»»åŠ¡å†²çª
            from app.models.analysis_task import TaskStatus
            from sqlalchemy import desc

            # æŸ¥æ‰¾æ‰€æœ‰æ´»è·ƒä»»åŠ¡ï¼ŒæŒ‰æ›´æ–°æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„ä¼˜å…ˆï¼‰
            all_active_tasks = self.db.query(AnalysisTask).filter(
                AnalysisTask.webhook_id == webhook_id,
                AnalysisTask.status == TaskStatus.ACTIVE
            ).order_by(desc(AnalysisTask.updated_at)).all()

            print(f"ğŸ” [DEBUG] æŸ¥æ‰¾æ´»è·ƒä»»åŠ¡: webhook_id={webhook_id}, status='active'")
            print(f"ğŸ“Š [DEBUG] æ‰¾åˆ° {len(all_active_tasks)} ä¸ªæ´»è·ƒçš„åˆ†æä»»åŠ¡")

            if not all_active_tasks:
                error_msg = f"æ²¡æœ‰æ‰¾åˆ°æ´»è·ƒçš„åˆ†æä»»åŠ¡: webhook {webhook_id}"
                print(f"âŒ [DEBUG] {error_msg}")
                print(f"   - å°è¯•æŸ¥æ‰¾æ‰€æœ‰çŠ¶æ€çš„ä»»åŠ¡...")
                all_tasks = self.db.query(AnalysisTask).filter(
                    AnalysisTask.webhook_id == webhook_id
                ).all()
                print(f"   - æ‰€æœ‰ä»»åŠ¡æ•°é‡: {len(all_tasks)}")
                for task in all_tasks:
                    print(f"     * ä»»åŠ¡ {task.id}: {task.name}, çŠ¶æ€: {task.status}")
                raise WebhookProcessorError(error_msg)

            # åªæ‰§è¡Œæœ€æ–°çš„ä¸€ä¸ªä»»åŠ¡ï¼Œç¡®ä¿ä¸€å¯¹ä¸€å…³ç³»
            if len(all_active_tasks) > 1:
                print(f"âš ï¸ [DEBUG] å‘ç°å¤šä¸ªæ´»è·ƒä»»åŠ¡ï¼Œåªæ‰§è¡Œæœ€æ–°çš„ä»»åŠ¡ä»¥é¿å…å†²çª")
                for i, task in enumerate(all_active_tasks):
                    status_icon = "ğŸ¯" if i == 0 else "â¸ï¸"
                    print(f"   {status_icon} ä»»åŠ¡ {task.id}: {task.name} (æ›´æ–°æ—¶é—´: {task.updated_at})")

            # åªå–æœ€æ–°çš„ä¸€ä¸ªä»»åŠ¡
            analysis_tasks = [all_active_tasks[0]]

            execution_log.append(f"æ‰¾åˆ° {len(analysis_tasks)} ä¸ªæ´»è·ƒçš„åˆ†æä»»åŠ¡")
            result["steps"].append({"step": "load_tasks", "success": True, "task_count": len(analysis_tasks)})

            # 1.5. é¢„æ£€æŸ¥å’ŒéªŒè¯é˜¶æ®µ - é˜²æ­¢é‡å¤æ‰§è¡Œ
            print(f"\nğŸ›¡ï¸ [DEBUG] æ­¥éª¤1.5: æ‰§è¡Œé¢„æ£€æŸ¥éªŒè¯")
            validation_result = await self._validate_webhook_execution(
                payload_data=payload_data,
                analysis_tasks=analysis_tasks,
                execution_id=execution_id,
                execution_log=execution_log
            )

            if not validation_result["should_execute"]:
                # ä»»åŠ¡è¢«è·³è¿‡ï¼Œè®°å½•åŸå› å¹¶è¿”å›æˆåŠŸçŠ¶æ€ï¼ˆé¿å…é‡å¤è§¦å‘ï¼‰
                skip_reason = validation_result["skip_reason"]
                print(f"â­ï¸ [DEBUG] ä»»åŠ¡æ‰§è¡Œè¢«è·³è¿‡: {skip_reason}")

                # è®°å½•è·³è¿‡äº‹ä»¶åˆ°WebhookLog
                from app.models.webhook_log_simple import WebhookLog
                skip_log = WebhookLog(
                    webhook_id=webhook_id,
                    request_id=f"skip_{execution_id}",
                    source_ip=client_ip,
                    user_agent=user_agent,
                    request_headers={"Content-Type": "application/json"},
                    request_payload=payload_data,
                    request_size_bytes=len(str(payload_data)),
                    response_status=200,  # æˆåŠŸçŠ¶æ€ï¼Œä½†è·³è¿‡æ‰§è¡Œ
                    response_time_ms=int((time.time() - start_time) * 1000),
                    is_valid=False,  # æ ‡è®°ä¸ºæ— æ•ˆï¼Œè¡¨ç¤ºè¢«è·³è¿‡
                    validation_errors=[skip_reason]
                )
                self.db.add(skip_log)
                self.db.commit()

                result.update({
                    "success": True,  # è¿”å›æˆåŠŸé¿å…é‡å¤è§¦å‘
                    "skipped": True,
                    "skip_reason": skip_reason,
                    "validation_details": validation_result.get("details", {}),
                    "processing_time_seconds": time.time() - start_time,
                    "end_time": datetime.utcnow().isoformat(),
                    "execution_log": execution_log + [f"ä»»åŠ¡è·³è¿‡: {skip_reason}"]
                })

                logger.info(f"Webhookä»»åŠ¡è¢«è·³è¿‡ {execution_id}: {skip_reason}")
                return result

            # 2. å¤„ç†æ¯ä¸ªåˆ†æä»»åŠ¡
            print(f"\nğŸ”„ [DEBUG] æ­¥éª¤2: å¼€å§‹å¤„ç† {len(analysis_tasks)} ä¸ªåˆ†æä»»åŠ¡")
            task_results = []
            
            for task in analysis_tasks:
                print(f"\nğŸ“ [DEBUG] å¤„ç†ä»»åŠ¡: {task.name} (ID: {task.id})")
                print(f"   - AIæ¨¡å‹ID: {task.ai_model_id}")
                print(f"   - å­˜å‚¨å‡­è¯: {task.enable_storage_credential}")
                print(f"   - æç¤ºè¯è®¾ç½®: {'æ˜¯' if task.prompt_template else 'å¦'}")
                
                try:
                    # åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•
                    print(f"ğŸ’¾ [DEBUG] åˆ›å»ºä»»åŠ¡æ‰§è¡Œè®°å½•...")
                    task_execution = TaskExecution(
                        task_id=task.id,  # ç°åœ¨å¯ä»¥å®‰å…¨è®¾ç½®task_idäº†
                        execution_id=execution_id,
                        execution_status=ExecutionStatus.PENDING,
                        webhook_payload=payload_data,
                        started_at=datetime.utcnow()
                    )
                    self.db.add(task_execution)
                    self.db.commit()
                    print(f"âœ… [DEBUG] ä»»åŠ¡æ‰§è¡Œè®°å½•åˆ›å»ºæˆåŠŸ")
                    
                    # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
                    task_execution.execution_status = ExecutionStatus.PROCESSING
                    self.db.commit()
                    print(f"ğŸ”„ [DEBUG] ä»»åŠ¡çŠ¶æ€æ›´æ–°ä¸ºPROCESSING")
                    
                    # å¤„ç†å•ä¸ªä»»åŠ¡
                    print(f"ğŸ¯ [DEBUG] å¼€å§‹æ‰§è¡Œå•ä¸ªä»»åŠ¡å¤„ç†é€»è¾‘...")
                    task_result = await self._process_single_task(
                        task, 
                        payload_data, 
                        execution_id,
                        execution_log,
                        task_execution
                    )
                    print(f"ğŸ [DEBUG] å•ä¸ªä»»åŠ¡å¤„ç†å®Œæˆ: æˆåŠŸ={task_result['success']}")
                    
                    task_results.append(task_result)
                    
                    # æ›´æ–°ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
                    task_execution.execution_status = ExecutionStatus.SUCCESS if task_result["success"] else ExecutionStatus.FAILED
                    task_execution.error_message = task_result.get("error")
                    task_execution.completed_at = datetime.utcnow()
                    
                    # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
                    processing_time = time.time() - start_time
                    task.update_execution_stats(
                        success=task_result["success"],
                        execution_time=processing_time,
                        tokens_used=task_result.get("tokens_used", 0),
                        cost=task_result.get("cost", 0.0)
                    )
                    
                    self.db.commit()
                    
                except Exception as e:
                    print(f"âŒ [DEBUG] å¤„ç†ä»»åŠ¡å¤±è´¥ {task.id}: {e}")
                    print(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                    import traceback
                    print(f"   - å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                    logger.error(f"å¤„ç†ä»»åŠ¡å¤±è´¥ {task.id}: {e}", exc_info=True)
                    
                    if task_execution:
                        task_execution.execution_status = ExecutionStatus.FAILED
                        task_execution.error_message = str(e)
                        task_execution.completed_at = datetime.utcnow()
                        
                        task.update_execution_stats(success=False)
                        self.db.commit()
                    
                    task_results.append({
                        "success": False,
                        "task_id": task.id,
                        "task_name": task.name,
                        "error": str(e)
                    })
            
            # 3. æ±‡æ€»ç»“æœ
            successful_tasks = [r for r in task_results if r["success"]]
            failed_tasks = [r for r in task_results if not r["success"]]
            
            result.update({
                "success": len(successful_tasks) > 0,
                "total_tasks": len(task_results),
                "successful_tasks": len(successful_tasks),
                "failed_tasks": len(failed_tasks),
                "task_results": task_results,
                "processing_time_seconds": time.time() - start_time,
                "end_time": datetime.utcnow().isoformat(),
                "execution_log": execution_log
            })
            
            logger.info(f"Webhookä»»åŠ¡å¤„ç†å®Œæˆ {execution_id}: {len(successful_tasks)}/{len(task_results)} æˆåŠŸ")
            
            return result
            
        except Exception as e:
            logger.error(f"Webhookä»»åŠ¡å¤„ç†å¤±è´¥ {execution_id}: {e}")
            
            result.update({
                "success": False,
                "error": str(e),
                "processing_time_seconds": time.time() - start_time,
                "end_time": datetime.utcnow().isoformat(),
                "execution_log": execution_log
            })
            
            return result
    
    async def _process_single_task(
        self,
        task: AnalysisTask,
        payload_data: Dict[str, Any],
        execution_id: str,
        execution_log: list,
        task_execution: TaskExecution
    ) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªåˆ†æä»»åŠ¡
        
        Args:
            task: åˆ†æä»»åŠ¡å¯¹è±¡
            payload_data: åŸå§‹webhookæ•°æ®
            execution_id: æ‰§è¡ŒID
            execution_log: æ‰§è¡Œæ—¥å¿—åˆ—è¡¨
            
        Returns:
            ä»»åŠ¡å¤„ç†ç»“æœ
        """
        task_start_time = time.time()
        task_result = {
            "success": False,
            "task_id": task.id,
            "task_name": task.name,
            "steps": [],
            "tokens_used": 0,
            "cost": 0.0
        }
        
        try:
            # åˆå§‹åŒ–å˜é‡é¿å…ä½œç”¨åŸŸé—®é¢˜
            source_field_key = None  # ä»webhookä¸­æå–çš„è§¦å‘å­—æ®µkey
            target_field_key = None  # ä»»åŠ¡é…ç½®ä¸­çš„ç›®æ ‡å†™å…¥å­—æ®µkey
            
            print(f"\nğŸš€ [TASK] å¼€å§‹å¤„ç†åˆ†æä»»åŠ¡: {task.name} (ID: {task.id})")
            logger.info(f"å¼€å§‹å¤„ç†åˆ†æä»»åŠ¡: {task.name} (ID: {task.id})")
            execution_log.append(f"å¼€å§‹å¤„ç†ä»»åŠ¡: {task.name}")
            
            # ç¬¬1æ­¥ï¼šæ•°æ®è§£æ - ä»é£ä¹¦Webhookä¸­æå–å…³é”®å­—æ®µ
            print(f"\nğŸ” [TASK] æ­¥éª¤1: è§£æé£ä¹¦Webhookæ•°æ®")
            logger.info("æ­¥éª¤1: è§£æé£ä¹¦Webhookæ•°æ®")
            parsed_data = {}
            
            try:
                # ä»payloadä¸­æå–å…³é”®å­—æ®µ
                if isinstance(payload_data, dict):
                    # æå–è®°å½•ID (payload.id)
                    record_id = None
                    if "payload" in payload_data and isinstance(payload_data["payload"], dict):
                        record_id = payload_data["payload"].get("id")
                    
                    # æå–å­—æ®µå€¼ (payload.changed_fields[0].cur_field_value)
                    field_value = None
                    if ("payload" in payload_data and 
                        isinstance(payload_data["payload"], dict) and
                        "changed_fields" in payload_data["payload"] and
                        isinstance(payload_data["payload"]["changed_fields"], list) and
                        len(payload_data["payload"]["changed_fields"]) > 0):
                        # changed_fieldsæ˜¯æ•°ç»„ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ çš„cur_field_value
                        first_changed_field = payload_data["payload"]["changed_fields"][0]
                        field_value = first_changed_field.get("cur_field_value")
                    else:
                        logger.warning(f"changed_fieldsæ•°æ®ç»“æ„ä¸æ­£ç¡®: {type(payload_data.get('payload', {}).get('changed_fields'))}")
                    
                    parsed_data = {
                        "record_id": record_id,
                        "field_value": field_value,
                        "raw_payload": payload_data
                    }
                    
                    print(f"âœ… [TASK] é£ä¹¦æ•°æ®è§£æ: record_id={record_id}, field_value={'å·²è·å–' if field_value else 'æœªè·å–'}")
                    execution_log.append(f"é£ä¹¦æ•°æ®è§£ææˆåŠŸ: record_id={record_id}, field_value={'å·²è·å–' if field_value else 'æœªè·å–'}")
                    task_result["steps"].append({
                        "step": "data_parsing",
                        "success": True,
                        "extracted_fields": {
                            "record_id": record_id is not None,
                            "field_value": field_value is not None
                        }
                    })
                    
                    if not record_id:
                        logger.warning("æœªèƒ½ä»payloadä¸­æå–record_id")
                    if not field_value:
                        logger.warning("æœªèƒ½ä»payloadä¸­æå–field_value")
                        
                else:
                    raise WebhookProcessorError("payloadæ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                    
            except Exception as e:
                logger.error(f"é£ä¹¦æ•°æ®è§£æå¤±è´¥: {e}")
                raise WebhookProcessorError(f"é£ä¹¦æ•°æ®è§£æå¤±è´¥: {e}")
            
            # ç¬¬2æ­¥ï¼šæ–‡ä»¶è·å–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            file_content = None
            file_info = {}
            
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å­˜å‚¨å‡­è¯åŠŸèƒ½
            if task.enable_storage_credential and task.storage_credential_id:
                logger.info("æ­¥éª¤2: è·å–æ–‡ä»¶å†…å®¹")
                task_execution.update_file_info()  # è®°å½•å¼€å§‹æ–‡ä»¶è·å–
                
                # è·å–å­˜å‚¨å‡­è¯
                storage_credential = self.db.query(StorageCredential).filter(
                    StorageCredential.id == task.storage_credential_id
                ).first()
                
                if not storage_credential:
                    raise WebhookProcessorError(f"å­˜å‚¨å‡­è¯ä¸å­˜åœ¨: {task.storage_credential_id}")
                
                # ä»æå–çš„æ•°æ®ä¸­æ„å»ºæ–‡ä»¶URLæˆ–è·¯å¾„
                # è¿™é‡Œå¯ä»¥åŸºäºpayload.changed_fields.pre_field_valueæ¥æ„å»ºæ–‡ä»¶è·¯å¾„
                file_path = None
                if field_value and isinstance(field_value, str):
                    # å¦‚æœpre_field_valueæ˜¯æ–‡ä»¶URLæˆ–è·¯å¾„
                    file_path = field_value
                elif record_id:
                    # æˆ–è€…åŸºäºrecord_idæ„å»ºæ–‡ä»¶è·¯å¾„
                    file_path = f"records/{record_id}/attachment"
                
                if file_path:
                    try:
                        # è·å–æ–‡ä»¶å†…å®¹
                        file_result = await file_service.get_file_with_credential(
                            file_path=file_path,
                            credential=storage_credential
                        )
                        
                        file_content = file_result["content"]
                        file_info = file_result["file_info"]
                        
                        # æ›´æ–°æ‰§è¡Œè®°å½•
                        task_execution.update_file_info(
                            file_url=file_path,
                            file_size=file_info.get("size", 0),
                            file_type=file_info.get("type"),
                            content_preview=file_content[:200] if file_content else None
                        )
                        
                        execution_log.append(f"æ–‡ä»¶è·å–æˆåŠŸ: {file_path} ({file_info.get('size', 0)} bytes)")
                        task_result["steps"].append({
                            "step": "file_retrieval",
                            "success": True,
                            "file_path": file_path,
                            "file_size": file_info.get("size", 0),
                            "file_type": file_info.get("type")
                        })
                        
                    except Exception as e:
                        logger.error(f"æ–‡ä»¶è·å–å¤±è´¥: {e}")
                        task_execution.error_message = f"æ–‡ä»¶è·å–å¤±è´¥: {str(e)}"
                        raise WebhookProcessorError(f"æ–‡ä»¶è·å–å¤±è´¥: {e}")
                else:
                    execution_log.append("è·³è¿‡æ–‡ä»¶è·å–ï¼ˆæœªæ‰¾åˆ°æ–‡ä»¶è·¯å¾„ï¼‰")
            else:
                execution_log.append("è·³è¿‡æ–‡ä»¶è·å–ï¼ˆåŠŸèƒ½æœªå¯ç”¨æˆ–æ— å­˜å‚¨å‡­è¯é…ç½®ï¼‰")
            
            # ç¬¬2.5æ­¥ï¼šå¯Œæ–‡æœ¬å­—æ®µè§£æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            rich_text_images = []
            if task.enable_rich_text_parsing:
                try:
                    print(f"\nğŸ–¼ï¸ [TASK] æ­¥éª¤2.5: å¤„ç†å¯Œæ–‡æœ¬å­—æ®µè§£æ")
                    logger.info("æ­¥éª¤2.5: å¤„ç†å¯Œæ–‡æœ¬å­—æ®µè§£æ")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ•°æ®æ¥è§£æå¯Œæ–‡æœ¬
                    if not (field_value and record_id):
                        print(f"âš ï¸ [TASK] ç¼ºå°‘å¯Œæ–‡æœ¬è§£ææ‰€éœ€æ•°æ® (record_id: {record_id}, field_value: {'æœ‰' if field_value else 'æ— '})")
                        execution_log.append("å¯Œæ–‡æœ¬è§£æ: ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œè·³è¿‡å¤„ç†")
                    else:
                        # ä»webhookæ•°æ®ä¸­æå–å¿…è¦çš„é¡¹ç›®ä¿¡æ¯
                        if 'payload' in payload_data:
                            payload = payload_data['payload']
                            project_key = payload.get('project_key')
                            work_item_type_key = payload.get('work_item_type_key')
                            work_item_id = str(payload.get('id', ''))
                            
                            # æå–å­—æ®µkeyï¼ˆä»changed_fieldsä¸­è·å–ï¼‰
                            if 'changed_fields' in payload and payload['changed_fields']:
                                # é€šå¸¸å–ç¬¬ä¸€ä¸ªchanged_fieldçš„field_key
                                source_field_key = payload['changed_fields'][0].get('field_key')
                            else:
                                source_field_key = None  # ç¡®ä¿å˜é‡æœ‰å®šä¹‰
                            
                            print(f"ğŸ” [TASK] ä»Webhookä¸­æå–é¡¹ç›®ä¿¡æ¯:")
                            print(f"   - project_key: {project_key}")
                            print(f"   - work_item_type_key: {work_item_type_key}")
                            print(f"   - work_item_id: {work_item_id}")
                            print(f"   - source_field_key: {source_field_key}")
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„é¡¹ç›®ä¿¡æ¯
                            if not all([project_key, work_item_type_key, work_item_id, source_field_key]):
                                print(f"âš ï¸ [TASK] ç¼ºå°‘å¯Œæ–‡æœ¬è§£æå¿…éœ€çš„é¡¹ç›®ä¿¡æ¯")
                                execution_log.append("å¯Œæ–‡æœ¬è§£æ: ç¼ºå°‘é¡¹ç›®ä¿¡æ¯ï¼Œè·³è¿‡å¤„ç†")
                            else:
                                # ä»ç¯å¢ƒå˜é‡è¯»å–é£ä¹¦APIé…ç½®
                                import os
                                fixed_api_config = {
                                    "plugin_id": os.getenv("FEISHU_PLUGIN_ID", ""),
                                    "plugin_secret": os.getenv("FEISHU_PLUGIN_SECRET", ""),
                                    "user_key": os.getenv("FEISHU_USER_KEY", "")
                                }
                                
                                # æ£€æŸ¥å¿…éœ€çš„é…ç½®æ˜¯å¦å­˜åœ¨
                                if not all(fixed_api_config.values()):
                                    print(f"âš ï¸ [TASK] é£ä¹¦APIé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡: FEISHU_PLUGIN_ID, FEISHU_PLUGIN_SECRET, FEISHU_USER_KEY")
                                    execution_log.append("å¯Œæ–‡æœ¬è§£æ: é£ä¹¦APIé…ç½®ç¼ºå¤±ï¼Œè·³è¿‡å¤„ç†")
                                else:
                                    print(f"ğŸ”§ [TASK] å¼€å§‹æŸ¥è¯¢å¯Œæ–‡æœ¬è¯¦æƒ…...")

                                    # å¯¼å…¥å¯Œæ–‡æœ¬è¯¦æƒ…æŸ¥è¯¢æœåŠ¡ï¼ˆjsonå·²åœ¨æ–‡ä»¶å¤´éƒ¨å¯¼å…¥ï¼‰
                                    from app.services.image_download_service import FeishuImageDownloadService
                                    import aiohttp

                                    # ç¬¬ä¸€æ­¥: è·å–plugin_token
                                    plugin_token = None
                                    try:
                                        download_service = FeishuImageDownloadService()
                                        plugin_token = await download_service.get_plugin_token(
                                            plugin_id=fixed_api_config["plugin_id"],
                                            plugin_secret=fixed_api_config["plugin_secret"]
                                        )
                                        print(f"âœ… [TASK] Plugin Tokenè·å–æˆåŠŸ")
                                    except Exception as token_error:
                                        print(f"âŒ [TASK] Plugin Tokenè·å–å¤±è´¥: {token_error}")
                                        execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: Plugin Tokenè·å–å¤±è´¥ - {token_error}")
                                
                                    # ç¬¬äºŒæ­¥: æŸ¥è¯¢å¯Œæ–‡æœ¬å­—æ®µè¯¦æƒ…
                                    if plugin_token:
                                        try:
                                            # æ„å»ºæŸ¥è¯¢å¯Œæ–‡æœ¬è¯¦æƒ…çš„è¯·æ±‚
                                            rich_text_url = f"https://project.feishu.cn/open_api/{project_key}/work_item/{work_item_type_key}/query"

                                            headers = {
                                                "X-PLUGIN-TOKEN": plugin_token,
                                                "X-USER-KEY": fixed_api_config["user_key"],
                                                "Content-Type": "application/json"
                                            }

                                            request_body = {
                                                "work_item_ids": [int(work_item_id)],
                                                "fields": [source_field_key],
                                                "expand": {
                                                    "need_workflow": False,
                                                    "relation_fields_detail": False,
                                                    "need_multi_text": True,
                                                    "need_user_detail": False,
                                                    "need_sub_task_parent": False
                                                }
                                            }

                                            print(f"ğŸ“¡ [TASK] æŸ¥è¯¢å¯Œæ–‡æœ¬è¯¦æƒ…: {rich_text_url}")
                                            print(f"   - è¯·æ±‚ä½“: {json.dumps(request_body, ensure_ascii=False)}")

                                            async with aiohttp.ClientSession() as session:
                                                async with session.post(rich_text_url, headers=headers, json=request_body) as response:
                                                    if response.status == 200:
                                                        rich_text_response = await response.json()
                                                        print(f"âœ… [TASK] å¯Œæ–‡æœ¬è¯¦æƒ…æŸ¥è¯¢æˆåŠŸ")

                                                        # è§£æå¯Œæ–‡æœ¬ä¸­çš„å›¾ç‰‡ä¿¡æ¯
                                                        await self._parse_rich_text_images(
                                                            rich_text_response=rich_text_response,
                                                            field_key=source_field_key,
                                                            project_key=project_key,
                                                            work_item_type_key=work_item_type_key,
                                                            work_item_id=work_item_id,
                                                            fixed_api_config=fixed_api_config,
                                                            rich_text_images=rich_text_images,
                                                            execution_log=execution_log
                                                        )
                                                    else:
                                                        error_text = await response.text()
                                                        print(f"âŒ [TASK] å¯Œæ–‡æœ¬è¯¦æƒ…æŸ¥è¯¢å¤±è´¥: {response.status} - {error_text}")
                                                        execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: è¯¦æƒ…æŸ¥è¯¢å¤±è´¥ - {response.status}")
                                        except Exception as query_error:
                                            print(f"âŒ [TASK] å¯Œæ–‡æœ¬è¯¦æƒ…æŸ¥è¯¢å¼‚å¸¸: {query_error}")
                                            execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: æŸ¥è¯¢å¼‚å¸¸ - {query_error}")
                        else:
                            print(f"âš ï¸ [TASK] Webhookæ•°æ®ä¸­ç¼ºå°‘payloadä¿¡æ¯")
                            execution_log.append("å¯Œæ–‡æœ¬è§£æ: Webhookæ•°æ®æ ¼å¼é”™è¯¯")
                            
                    print(f"ğŸ“Š [TASK] å¯Œæ–‡æœ¬è§£æå®Œæˆ: æˆåŠŸå¤„ç† {len(rich_text_images)} å¼ å›¾ç‰‡")
                    execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: å¤„ç†äº† {len(rich_text_images)} å¼ å›¾ç‰‡")
                    
                except Exception as rich_error:
                    print(f"âŒ [TASK] å¯Œæ–‡æœ¬è§£æå¤±è´¥: {rich_error}")
                    logger.error(f"å¯Œæ–‡æœ¬è§£æå¤±è´¥: {rich_error}")
                    execution_log.append(f"å¯Œæ–‡æœ¬è§£æå¤±è´¥: {rich_error}")
                    # ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡ŒAIåˆ†æ
            else:
                print(f"â„¹ï¸ [TASK] å¯Œæ–‡æœ¬è§£ææœªå¯ç”¨æˆ–æœªé…ç½®")
                execution_log.append("è·³è¿‡å¯Œæ–‡æœ¬è§£æï¼ˆæœªå¯ç”¨æˆ–æœªé…ç½®ï¼‰")

            # ç¬¬2.7æ­¥ï¼šå¤šå­—æ®µæŸ¥è¯¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            additional_field_data = {}
            if task.enable_multi_field_analysis and task.multi_field_config:
                try:
                    print(f"\nğŸ” [TASK] æ­¥éª¤2.7: æ‰§è¡Œå¤šå­—æ®µæŸ¥è¯¢")
                    logger.info("æ­¥éª¤2.7: æ‰§è¡Œå¤šå­—æ®µæŸ¥è¯¢")

                    # è°ƒç”¨å¤šå­—æ®µæŸ¥è¯¢æ–¹æ³•
                    additional_field_data = await self._query_additional_fields(
                        task=task,
                        payload_data=payload_data,
                        execution_log=execution_log
                    )

                    print(f"âœ… [TASK] å¤šå­—æ®µæŸ¥è¯¢å®Œæˆ: è·å–åˆ° {len(additional_field_data)} ä¸ªå­—æ®µ")
                    execution_log.append(f"å¤šå­—æ®µæŸ¥è¯¢: è·å–åˆ° {len(additional_field_data)} ä¸ªå­—æ®µ")
                    task_result["steps"].append({
                        "step": "multi_field_query",
                        "success": True,
                        "fields_count": len(additional_field_data),
                        "fields": list(additional_field_data.keys())
                    })

                except Exception as multi_field_error:
                    print(f"âŒ [TASK] å¤šå­—æ®µæŸ¥è¯¢å¤±è´¥: {multi_field_error}")
                    logger.error(f"å¤šå­—æ®µæŸ¥è¯¢å¤±è´¥: {multi_field_error}")
                    execution_log.append(f"å¤šå­—æ®µæŸ¥è¯¢å¤±è´¥: {multi_field_error}")
                    # ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡ŒAIåˆ†æ
            else:
                print(f"â„¹ï¸ [TASK] å¤šå­—æ®µæŸ¥è¯¢æœªå¯ç”¨æˆ–æœªé…ç½®")
                execution_log.append("è·³è¿‡å¤šå­—æ®µæŸ¥è¯¢ï¼ˆæœªå¯ç”¨æˆ–æœªé…ç½®ï¼‰")

            # ç¬¬3æ­¥ï¼šAIåˆ†æ
            print(f"\nğŸ¤– [TASK] æ­¥éª¤3: æ‰§è¡ŒAIåˆ†æ")
            logger.info("æ­¥éª¤3: æ‰§è¡ŒAIåˆ†æ")
            
            # è·å–AIæ¨¡å‹
            print(f"ğŸ” [TASK] æŸ¥æ‰¾AIæ¨¡å‹: {task.ai_model_id}")
            ai_model = self.db.query(AIModel).filter(
                AIModel.id == task.ai_model_id
            ).first()
            
            if not ai_model:
                error_msg = f"AIæ¨¡å‹ä¸å­˜åœ¨: {task.ai_model_id}"
                print(f"âŒ [TASK] {error_msg}")
                raise WebhookProcessorError(error_msg)
            
            print(f"âœ… [TASK] æ‰¾åˆ°AIæ¨¡å‹: {ai_model.name} ({ai_model.model_type})")
            print(f"   - APIå¯†é’¥: {'å·²è®¾ç½®' if ai_model.api_key else 'æœªè®¾ç½®'}")
            
            # æ„å»ºåˆ†æå†…å®¹ - åŒ…å«webhookæ•°æ®å’Œæ–‡ä»¶å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
            analysis_content = {
                "record_id": record_id,
                "field_value": field_value,
                "file_content": file_content or None,
                "webhook_payload": payload_data
            }
            
            # æ„å»ºæœ€ç»ˆçš„åˆ†ææç¤ºè¯ï¼ˆæ”¯æŒå¤šå­—æ®µæ¨¡æ¿æ¸²æŸ“ï¼‰
            user_prompt = task.user_prompt_template or "ç»¼åˆå¯¹æ¯”åˆ†æä¸€ä¸‹è¿™äº›å›¾ç‰‡æ•°æ®çš„æƒ…å†µ"

            # å‡†å¤‡å¯Œæ–‡æœ¬å­—æ®µçš„çº¯æ–‡æœ¬å†…å®¹
            rich_text_content = ""
            if field_value:
                rich_text_content = self._extract_rich_text_content(field_value)

            if task.enable_multi_field_analysis and additional_field_data:
                # ä½¿ç”¨å¤šå­—æ®µæ¨¡æ¿æ¸²æŸ“
                print(f"ğŸ”„ [TASK] ä½¿ç”¨å¤šå­—æ®µæ¨¡æ¿æ¸²æŸ“")
                print(f"   - å¯ç”¨å­—æ®µ: {list(additional_field_data.keys())}")

                # å°†å¯Œæ–‡æœ¬è§¦å‘å­—æ®µæ·»åŠ åˆ°å­—æ®µæ•°æ®ä¸­ï¼Œæ”¯æŒå ä½ç¬¦ä½¿ç”¨
                additional_field_data['field_value'] = rich_text_content
                additional_field_data['trigger_field'] = rich_text_content  # æä¾›åˆ«å

                print(f"   - å¯Œæ–‡æœ¬å†…å®¹é•¿åº¦: {len(rich_text_content)} å­—ç¬¦")
                print(f"   - å¯ç”¨å ä½ç¬¦: {list(additional_field_data.keys())}")

                # æ¸²æŸ“ç”¨æˆ·æç¤ºè¯æ¨¡æ¿ï¼ˆç°åœ¨æ”¯æŒ {field_value} å’Œ {trigger_field} å ä½ç¬¦ï¼‰
                rendered_prompt = self._render_template_with_fields(user_prompt, additional_field_data)

                # å¦‚æœç”¨æˆ·åœ¨æç¤ºè¯ä¸­ä½¿ç”¨äº†å ä½ç¬¦ï¼Œåˆ™ç›´æ¥ä½¿ç”¨æ¸²æŸ“ç»“æœ
                # å¦åˆ™ä¿æŒå…¼å®¹æ€§ï¼Œåœ¨æœ«å°¾æ·»åŠ è§¦å‘å­—æ®µå†…å®¹
                if '{field_value}' in user_prompt or '{trigger_field}' in user_prompt:
                    # ç”¨æˆ·ä¸»åŠ¨ä½¿ç”¨äº†å¯Œæ–‡æœ¬å ä½ç¬¦ï¼Œå®Œå…¨ç”±ç”¨æˆ·æ§åˆ¶ä½ç½®
                    final_prompt = rendered_prompt
                    print(f"   - æ£€æµ‹åˆ°å¯Œæ–‡æœ¬å ä½ç¬¦ä½¿ç”¨ï¼Œç”±ç”¨æˆ·æ§åˆ¶ä½ç½®")
                else:
                    # å‘åå…¼å®¹ï¼šåœ¨æœ«å°¾æ·»åŠ è§¦å‘å­—æ®µå†…å®¹
                    final_prompt = f"""{rendered_prompt}

è§¦å‘å­—æ®µå†…å®¹ï¼š{rich_text_content}

æ³¨æ„ï¼šä»¥ä¸Šä¿¡æ¯åŒ…å«äº†å·¥ä½œé¡¹çš„å¤šä¸ªå­—æ®µæ•°æ®ï¼Œè¯·ç»¼åˆåˆ†æã€‚"""
                    print(f"   - æœªæ£€æµ‹åˆ°å¯Œæ–‡æœ¬å ä½ç¬¦ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼")

                print(f"   - æ¸²æŸ“åçš„æç¤ºè¯é•¿åº¦: {len(final_prompt)}")
            else:
                # ä½¿ç”¨åŸæœ‰çš„å•å­—æ®µæ–¹å¼ï¼Œä½†æ”¯æŒ {field_value} å ä½ç¬¦
                if '{field_value}' in user_prompt:
                    # ç”¨æˆ·åœ¨å•å­—æ®µæ¨¡å¼ä¸‹ä½¿ç”¨äº†å ä½ç¬¦
                    field_data = {'field_value': rich_text_content}
                    final_prompt = self._render_template_with_fields(user_prompt, field_data)
                    print(f"ğŸ”„ [TASK] å•å­—æ®µæ¨¡å¼ä½¿ç”¨å ä½ç¬¦æ¸²æŸ“")
                else:
                    # å‘åå…¼å®¹ï¼šä¿æŒåŸæœ‰çš„å›ºå®šæ ¼å¼
                    final_prompt = f"""{user_prompt}

å¯Œæ–‡æœ¬å­—æ®µå†…å®¹ï¼š{rich_text_content}"""
                    print(f"â„¹ï¸ [TASK] å•å­—æ®µå…¼å®¹æ¨¡å¼")
            
            # è®°å½•AIè¯·æ±‚
            print(f"ğŸ“ [TASK] è®°å½•AIè¯·æ±‚æç¤ºè¯ (é•¿åº¦: {len(final_prompt)})")
            print(f"ğŸ“ [TASK] ä½¿ç”¨çš„ç”¨æˆ·æç¤ºè¯: {user_prompt[:100]}...")
            task_execution.update_ai_request(final_prompt)
            
            try:
                # è°ƒç”¨AIæœåŠ¡
                print(f"ğŸ¤– [TASK] è°ƒç”¨AIæœåŠ¡...")
                print(f"   - æ¨¡å‹ID: {ai_model.id}")
                print(f"   - max_tokens: {task.max_tokens or 1000}")
                print(f"   - temperature: {task.temperature or 0.7}")
                
                # æ„å»ºAIåˆ†æè¯·æ±‚å‚æ•°ï¼ˆä»»åŠ¡é…ç½®ä¼˜å…ˆï¼‰
                model_config = {
                    "provider": _get_provider_from_model_type(ai_model.model_type),
                    "model_name": ai_model.model_name or ai_model.name,
                    "api_key": ai_model.api_key,
                    "api_endpoint": ai_model.api_endpoint,
                    "temperature": float(task.temperature) if task.temperature is not None else (float(ai_model.temperature) if ai_model.temperature else 0.7),
                    "max_tokens": task.max_tokens or 1000,
                    "use_proxy": getattr(ai_model, 'use_proxy', False),
                    "proxy_url": getattr(ai_model, 'proxy_url', None) if getattr(ai_model, 'use_proxy', False) else None
                }
                
                print(f"âš™ï¸ [TASK] ä½¿ç”¨æ¸©åº¦: {model_config['temperature']} (ä»»åŠ¡:{task.temperature}/æ¨¡å‹:{ai_model.temperature})")
                
                # æ„å»ºåˆ†æè¯·æ±‚
                analysis_request = {
                    "model_config": model_config,
                    "prompt": final_prompt,
                    "data_content": file_content or "",
                    "file_contents": [],
                    "rich_text_images": rich_text_images,  # åŒ…å«ä»å¯Œæ–‡æœ¬å­—æ®µè§£æçš„å›¾ç‰‡
                    "context": {
                        "record_id": record_id,
                        "field_value": field_value,
                        "rich_text_enabled": task.enable_rich_text_parsing,
                        "images_count": len(rich_text_images)
                    }
                }
                
                print(f"ğŸ“ [TASK] AIåˆ†æè¯·æ±‚: å¯Œæ–‡æœ¬å›¾ç‰‡{len(rich_text_images)}å¼ , æç¤ºè¯{len(final_prompt)}å­—ç¬¦")
                
                ai_result = await ai_service.analyze_content(analysis_request)
                
                
                # æ£€æŸ¥AIåˆ†ææ˜¯å¦æˆåŠŸ
                if not ai_result.get("success", False):
                    error_msg = ai_result.get("error", "AIåˆ†æå¤±è´¥ï¼šæœªçŸ¥é”™è¯¯")
                    raise Exception(error_msg)
                
                analysis_result = ai_result["content"]
                
                # å¤„ç†tokenä½¿ç”¨æƒ…å†µ - analyze_contentè¿”å›çš„usageç»“æ„
                usage_info = ai_result.get("usage", {})
                tokens_used = usage_info.get("total_tokens", 0)
                if not tokens_used:
                    # å°è¯•å¤‡ç”¨å­—æ®µ
                    tokens_used = (usage_info.get("input_tokens", 0) + 
                                 usage_info.get("output_tokens", 0))
                
                # è®¡ç®—åŸºæœ¬æˆæœ¬ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”æ ¹æ®æ¨¡å‹å®šä»·ï¼‰
                cost = 0.0  # æš‚æ—¶è®¾ä¸º0ï¼Œåç»­å¯ä»¥æ ¹æ®æ¨¡å‹é…ç½®è®¡ç®—
                
                print(f"ğŸ“Š [TASK] AIåˆ†æå®Œæˆ: {len(analysis_result)}å­—ç¬¦, {tokens_used}tokens, æˆæœ¬${cost:.4f}")
                logger.info(f"AIåˆ†æç»“æœé¢„è§ˆ: {analysis_result[:200]}...")
                
                # è®°å½•AIå“åº”
                task_execution.update_ai_response(
                    response=analysis_result,
                    metadata=ai_result,
                    tokens_used=tokens_used,
                    cost=cost
                )
                
                task_result["analysis_result"] = analysis_result
                task_result["tokens_used"] = tokens_used
                task_result["cost"] = cost
                
                execution_log.append(f"AIåˆ†æå®Œæˆ: {tokens_used} tokens, æˆæœ¬: ${cost:.4f}")
                task_result["steps"].append({
                    "step": "ai_analysis", 
                    "success": True,
                    "model_name": ai_model.name,
                    "tokens_used": tokens_used,
                    "cost": cost
                })
                
            except Exception as e:
                print(f"âŒ [TASK] AIåˆ†æå¤±è´¥: {e}")
                print(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"   - å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                
                logger.error(f"AIåˆ†æå¤±è´¥: {e}", exc_info=True)
                task_execution.error_message = f"AIåˆ†æå¤±è´¥: {str(e)}"
                raise WebhookProcessorError(f"AIåˆ†æå¤±è´¥: {e}")
            
            # ç¬¬4æ­¥ï¼šé£ä¹¦ç»“æœå›å†™
            print(f"\nğŸš€ [TASK] æ­¥éª¤4: æ£€æŸ¥é£ä¹¦å›å†™é…ç½®")
            print(f"   - é£ä¹¦é…ç½®: {'å·²è®¾ç½®' if task.feishu_write_config else 'æœªè®¾ç½®'}")
            print(f"   - record_id: {record_id}")
            
            if task.feishu_write_config and record_id:
                print(f"ğŸš€ [TASK] å¼€å§‹å›å†™åˆ†æç»“æœåˆ°é£ä¹¦...")
                logger.info("æ­¥éª¤4: å›å†™åˆ†æç»“æœåˆ°é£ä¹¦")
                
                try:
                    # ä»webhookæ•°æ®ä¸­æå–å¿…è¦çš„é¡¹ç›®ä¿¡æ¯ï¼ˆä¸å¯Œæ–‡æœ¬è§£æä¸­çš„é€»è¾‘ç›¸åŒï¼‰
                    if 'payload' in payload_data:
                        payload = payload_data['payload']
                        project_key = payload.get('project_key')
                        work_item_type_key = payload.get('work_item_type_key')
                        work_item_id = str(payload.get('id', ''))
                        
                        # ä»ä»»åŠ¡é…ç½®ä¸­è·å–ç›®æ ‡å­—æ®µIDï¼ˆä¸æ˜¯webhookä¸­çš„field_keyï¼‰
                        target_field_key = None
                        if task.feishu_write_config and isinstance(task.feishu_write_config, dict):
                            target_field_key = task.feishu_write_config.get('field_id')
                        
                        print(f"ğŸ¯ [TASK] å›å†™ç›®æ ‡å­—æ®µæ£€æŸ¥:")
                        print(f"   - ä»»åŠ¡é…ç½®çš„ç›®æ ‡å­—æ®µ: {target_field_key}")
                        print(f"   - feishu_write_config: {task.feishu_write_config}")
                        
                        print(f"ğŸ” [TASK] ä»Webhookä¸­æå–é£ä¹¦å›å†™ä¿¡æ¯:")
                        print(f"   - project_key: {project_key}")
                        print(f"   - work_item_type_key: {work_item_type_key}")
                        print(f"   - work_item_id: {work_item_id}")
                        print(f"   - ç›®æ ‡å­—æ®µ: {target_field_key}")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„é¡¹ç›®ä¿¡æ¯ï¼ˆä½¿ç”¨ç›®æ ‡å­—æ®µï¼‰
                        if not all([project_key, work_item_type_key, work_item_id, target_field_key]):
                            missing = []
                            if not project_key: missing.append('project_key')
                            if not work_item_type_key: missing.append('work_item_type_key')
                            if not work_item_id: missing.append('work_item_id')
                            if not target_field_key: missing.append('target_field_key(ä»»åŠ¡é…ç½®)')
                            raise WebhookProcessorError(f"ç¼ºå°‘é£ä¹¦å›å†™å¿…éœ€çš„é¡¹ç›®ä¿¡æ¯: {', '.join(missing)}")
                        
                        # ä»ç¯å¢ƒå˜é‡è¯»å–é£ä¹¦APIé…ç½®ï¼ˆä¸å¯Œæ–‡æœ¬è§£æç›¸åŒï¼‰
                        import os
                        fixed_api_config = {
                            "plugin_id": os.getenv("FEISHU_PLUGIN_ID", ""),
                            "plugin_secret": os.getenv("FEISHU_PLUGIN_SECRET", ""),
                            "user_key": os.getenv("FEISHU_USER_KEY", "")
                        }
                        
                        # æ£€æŸ¥å¿…éœ€çš„é…ç½®æ˜¯å¦å­˜åœ¨
                        if not all(fixed_api_config.values()):
                            raise WebhookProcessorError("é£ä¹¦APIé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡: FEISHU_PLUGIN_ID, FEISHU_PLUGIN_SECRET, FEISHU_USER_KEY")
                        
                        # ç¬¬ä¸€æ­¥ï¼šè·å–plugin_token
                        print(f"ğŸ“¡ [TASK] è·å–Plugin Token...")
                        from app.services.image_download_service import FeishuImageDownloadService
                        
                        download_service = FeishuImageDownloadService()
                        plugin_token = await download_service.get_plugin_token(
                            plugin_id=fixed_api_config["plugin_id"],
                            plugin_secret=fixed_api_config["plugin_secret"]
                        )
                        print(f"âœ… [TASK] Plugin Tokenè·å–æˆåŠŸ")
                        
                        # ç¬¬äºŒæ­¥ï¼šå°†AIåˆ†æç»“æœè½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼
                        print(f"ğŸ“ [TASK] è½¬æ¢AIåˆ†æç»“æœä¸ºé£ä¹¦å¯Œæ–‡æœ¬æ ¼å¼...")
                        
                        try:
                            from app.utils.markdown_converter import convert_markdown_to_feishu
                            rich_text_content = convert_markdown_to_feishu(analysis_result)
                            print(f"âœ… [TASK] æˆåŠŸè½¬æ¢ä¸ºå¯Œæ–‡æœ¬ï¼ŒåŒ…å« {len(rich_text_content) if isinstance(rich_text_content, list) else 1} ä¸ªå†…å®¹å—")
                            field_value = rich_text_content
                        except Exception as convert_error:
                            print(f"âš ï¸ [TASK] å¯Œæ–‡æœ¬è½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼: {convert_error}")
                            field_value = analysis_result
                        
                        # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºé£ä¹¦é¡¹ç›®æ•°æ®å†™å…¥è¯·æ±‚
                        update_url = f"https://project.feishu.cn/open_api/{project_key}/work_item/{work_item_type_key}/{work_item_id}"
                        
                        headers = {
                            "Content-Type": "application/json",
                            "X-PLUGIN-TOKEN": plugin_token,
                            "X-USER-KEY": fixed_api_config["user_key"]
                        }
                        
                        # æŒ‰ç…§æ–‡æ¡£è¦æ±‚çš„è¯·æ±‚ä½“æ ¼å¼ï¼ˆä½¿ç”¨ç›®æ ‡å­—æ®µï¼‰
                        request_body = {
                            "update_fields": [{
                                "field_key": target_field_key,
                                "field_value": field_value,
                                "target_state": {
                                    "state_key": "",
                                    "transition_id": 0
                                },
                                "field_type_key": "",
                                "field_alias": "",
                                "help_description": ""
                            }]
                        }
                        
                        print(f"ğŸ“¡ [TASK] å‘é€é£ä¹¦å†™å…¥è¯·æ±‚åˆ°: {update_url}")
                        print(f"   - è¯·æ±‚å¤´: X-PLUGIN-TOKENå·²è®¾ç½®, X-USER-KEY={fixed_api_config['user_key']}")
                        
                        # ç¬¬å››æ­¥ï¼šå‘é€PUTè¯·æ±‚åˆ°é£ä¹¦é¡¹ç›®API
                        import aiohttp
                        async with aiohttp.ClientSession() as session:
                            async with session.put(update_url, headers=headers, json=request_body) as response:
                                response_text = await response.text()
                                print(f"ğŸ“Š [TASK] é£ä¹¦APIå“åº”çŠ¶æ€: {response.status}")
                                print(f"ğŸ“Š [TASK] é£ä¹¦APIå“åº”å†…å®¹: {response_text[:200]}...")
                                
                                try:
                                    response_json = await response.json() if response.status != 204 else {}
                                except:
                                    response_json = {"raw_response": response_text}
                                
                                # è®°å½•é£ä¹¦æ›´æ–°ç»“æœ
                                task_execution.update_feishu_result(
                                    feishu_task_id=work_item_id,
                                    feishu_response=response_json,
                                    fields_updated={target_field_key: str(field_value)[:200] + "..." if len(str(field_value)) > 200 else str(field_value)}
                                )
                                
                                if response.status in [200, 204]:
                                    print(f"âœ… [TASK] é£ä¹¦æ•°æ®å†™å…¥æˆåŠŸ")
                                    execution_log.append(f"é£ä¹¦å›å†™æˆåŠŸ: work_item_id={work_item_id}, target_field={target_field_key}")
                                    task_result["steps"].append({
                                        "step": "feishu_writeback",
                                        "success": True,
                                        "work_item_id": work_item_id,
                                        "target_field_key": target_field_key,
                                        "response_status": response.status
                                    })
                                else:
                                    error_msg = f"é£ä¹¦APIé”™è¯¯ ({response.status}): {response_text}"
                                    print(f"âŒ [TASK] {error_msg}")
                                    raise WebhookProcessorError(error_msg)
                    else:
                        raise WebhookProcessorError("Webhookæ•°æ®ä¸­ç¼ºå°‘payloadä¿¡æ¯")
                        
                except Exception as e:
                    print(f"âŒ [TASK] é£ä¹¦å›å†™å¤±è´¥: {e}")
                    logger.error(f"é£ä¹¦å›å†™å¤±è´¥: {e}")
                    execution_log.append(f"é£ä¹¦å›å†™å¤±è´¥: {e}")
                    # ä¸ä¸­æ–­ä¸»æµç¨‹ï¼Œæ ‡è®°ä¸ºéƒ¨åˆ†æˆåŠŸ
                    task_result["steps"].append({
                        "step": "feishu_writeback",
                        "success": False,
                        "error": str(e)
                    })
            else:
                print(f"â„¹ï¸ [TASK] è·³è¿‡é£ä¹¦å›å†™ï¼šé…ç½®æœªå¯ç”¨æˆ–ç¼ºå°‘record_id")
                execution_log.append("è·³è¿‡é£ä¹¦å›å†™ï¼šé…ç½®æœªå¯ç”¨æˆ–ç¼ºå°‘å¿…è¦ä¿¡æ¯")
            
            # ä»»åŠ¡å¤„ç†æˆåŠŸ - æ ‡è®°æ‰§è¡Œå®Œæˆ
            print(f"\nğŸ‰ [TASK] ä»»åŠ¡å¤„ç†æˆåŠŸ! æ ‡è®°ä¸ºå®ŒæˆçŠ¶æ€")
            # ä¿å­˜æ‰§è¡Œæ—¥å¿—
            task_execution.update_execution_log(execution_log)
            task_execution.mark_completed(
                status=ExecutionStatus.SUCCESS,
                error_message=None,
                error_code=None
            )
            
            task_result.update({
                "success": True,
                "analysis_result": analysis_result,
                "processing_time_seconds": time.time() - task_start_time,
                "message": "ä»»åŠ¡å¤„ç†æˆåŠŸ",
                "execution_id": execution_id
            })
            
            # æäº¤æ•°æ®åº“å˜æ›´
            self.db.commit()
            
            logger.info(f"åˆ†æä»»åŠ¡å¤„ç†æˆåŠŸ: {task.name}")
            return task_result
            
        except Exception as e:
            print(f"\nâŒ [TASK] åˆ†æä»»åŠ¡å¤„ç†å¤±è´¥ {task.name}: {e}")
            print(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            import traceback
            print(f"   - å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            logger.error(f"åˆ†æä»»åŠ¡å¤„ç†å¤±è´¥ {task.name}: {e}", exc_info=True)
            
            # æ ‡è®°æ‰§è¡Œå¤±è´¥
            if 'task_execution' in locals():
                # åœ¨å¤±è´¥æ—¥å¿—ä¸­æ·»åŠ é”™è¯¯ä¿¡æ¯
                execution_log.append(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
                # ä¿å­˜æ‰§è¡Œæ—¥å¿—
                task_execution.update_execution_log(execution_log)
                task_execution.mark_completed(
                    status=ExecutionStatus.FAILED,
                    error_message=str(e),
                    error_code=type(e).__name__
                )
                self.db.commit()
            
            task_result.update({
                "success": False,
                "error": str(e),
                "processing_time_seconds": time.time() - task_start_time,
                "execution_id": execution_id if 'execution_id' in locals() else None
            })
            
            return task_result
    
    def _render_template(self, template: str, context: Dict[str, Any]) -> str:
        """æ¸²æŸ“æ¨¡æ¿å­—ç¬¦ä¸²"""
        if not template:
            return ""
        
        try:
            # ç®€å•çš„æ¨¡æ¿æ›¿æ¢ï¼Œä½¿ç”¨ {{variable}} è¯­æ³•
            import re
            
            def replace_var(match):
                var_name = match.group(1)
                return str(context.get(var_name, f"{{{{{var_name}}}}}"))
            
            return re.sub(r'\{\{([^}]+)\}\}', replace_var, template)
            
        except Exception as e:
            logger.error(f"æ¨¡æ¿æ¸²æŸ“å¤±è´¥: {e}")
            return template

    async def _parse_rich_text_images(
        self,
        rich_text_response: Dict[str, Any],
        field_key: str,
        project_key: str,
        work_item_type_key: str,
        work_item_id: str,
        fixed_api_config: Dict[str, str],
        rich_text_images: list,
        execution_log: list
    ) -> None:
        """
        ä»å¯Œæ–‡æœ¬è¯¦æƒ…å“åº”ä¸­è§£æå›¾ç‰‡ä¿¡æ¯å¹¶ä¸‹è½½å›¾ç‰‡
        
        Args:
            rich_text_response: å¯Œæ–‡æœ¬è¯¦æƒ…APIå“åº”
            field_key: å­—æ®µkey
            project_key: é¡¹ç›®key
            work_item_type_key: å·¥ä½œé¡¹ç±»å‹key
            work_item_id: å·¥ä½œé¡¹ID
            fixed_api_config: å›ºå®šAPIé…ç½®
            rich_text_images: å›¾ç‰‡åˆ—è¡¨ï¼ˆè¾“å‡ºï¼‰
            execution_log: æ‰§è¡Œæ—¥å¿—
        """
        try:
            # ä»å“åº”ä¸­æå–multi_textsæ•°æ®
            if 'data' not in rich_text_response or not rich_text_response['data']:
                print(f"âŒ [TASK] å¯Œæ–‡æœ¬è¯¦æƒ…å“åº”ä¸­æ— dataå­—æ®µ")
                return
            
            work_item_data = rich_text_response['data'][0] if rich_text_response['data'] else None
            if not work_item_data or 'multi_texts' not in work_item_data:
                print(f"âŒ [TASK] å¯Œæ–‡æœ¬è¯¦æƒ…ä¸­æ— multi_textsæ•°æ®")
                return
            
            # æŸ¥æ‰¾å¯¹åº”field_keyçš„å¯Œæ–‡æœ¬æ•°æ®
            target_multi_text = None
            for multi_text in work_item_data['multi_texts']:
                if multi_text.get('field_key') == field_key:
                    target_multi_text = multi_text
                    break
            
            if not target_multi_text:
                print(f"âŒ [TASK] æœªæ‰¾åˆ°å­—æ®µ {field_key} çš„å¯Œæ–‡æœ¬æ•°æ®")
                return
            
            field_value = target_multi_text.get('field_value', {})
            doc_content = field_value.get('doc', '')
            
            if not doc_content:
                print(f"âŒ [TASK] å¯Œæ–‡æœ¬å­—æ®µ {field_key} æ— docå†…å®¹")
                return
            
            print(f"âœ… [TASK] æ‰¾åˆ°å¯Œæ–‡æœ¬docå†…å®¹: {len(doc_content)} å­—ç¬¦")
            
            # è§£ædocå†…å®¹ä¸­çš„å›¾ç‰‡ä¿¡æ¯
            import json
            import re
            
            try:
                # docæ˜¯JSONå­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ
                doc_data = json.loads(doc_content)
                images_found = []
                
                # é€’å½’æœç´¢æ‰€æœ‰opsä¸­çš„imageå±æ€§
                def find_images_in_ops(ops_data):
                    if isinstance(ops_data, dict):
                        if ops_data.get('attributes', {}).get('image') == 'true':
                            # æ‰¾åˆ°å›¾ç‰‡
                            uuid = ops_data['attributes'].get('uuid')
                            src = ops_data['attributes'].get('src')
                            if uuid:
                                images_found.append({
                                    'uuid': uuid,
                                    'src': src,
                                    'width': ops_data['attributes'].get('width'),
                                })
                        
                        # é€’å½’æœç´¢å­å¯¹è±¡
                        for value in ops_data.values():
                            if isinstance(value, (dict, list)):
                                find_images_in_ops(value)
                    elif isinstance(ops_data, list):
                        for item in ops_data:
                            find_images_in_ops(item)
                
                find_images_in_ops(doc_data)
                
                print(f"ğŸ“Š [TASK] è§£æåˆ° {len(images_found)} å¼ å›¾ç‰‡")
                
                if not images_found:
                    print(f"â„¹ï¸ [TASK] å¯Œæ–‡æœ¬å­—æ®µä¸­æœªå‘ç°å›¾ç‰‡")
                    execution_log.append("å¯Œæ–‡æœ¬è§£æ: æœªå‘ç°å›¾ç‰‡å†…å®¹")
                    return
                
                # ä¸‹è½½æ¯å¼ å›¾ç‰‡
                from app.services.image_download_service import FeishuImageDownloadService
                download_service = FeishuImageDownloadService()
                
                for i, img_info in enumerate(images_found):
                    try:
                        img_uuid = img_info['uuid']
                        print(f"ğŸ“¥ [TASK] ä¸‹è½½å›¾ç‰‡ {i+1}/{len(images_found)}: {img_uuid}")
                        
                        # ä½¿ç”¨é™„ä»¶ä¸‹è½½API
                        download_result = await download_service.download_attachment_with_auto_auth(
                            project_key=project_key,
                            work_item_type_key=work_item_type_key,
                            work_item_id=work_item_id,
                            file_uuid=img_uuid,
                            plugin_id=fixed_api_config["plugin_id"],
                            plugin_secret=fixed_api_config["plugin_secret"],
                            user_key=fixed_api_config["user_key"],
                            save_to_file=False  # ä¸ä¿å­˜æ–‡ä»¶ï¼Œç›´æ¥è·å–base64æ•°æ®
                        )
                        
                        if download_result.get('success') and download_result.get('image_data_base64'):
                            # æ·»åŠ åˆ°å›¾ç‰‡åˆ—è¡¨
                            rich_text_images.append({
                                "uuid": img_uuid,
                                "base64": download_result['image_data_base64'],
                                "size": download_result.get('actual_size', 0),
                                "type": download_result.get('content_type', 'image/png'),
                                "source": "rich_text_field",
                                "src": img_info.get('src', ''),
                                "width": img_info.get('width')
                            })
                            print(f"âœ… [TASK] å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_uuid}, å¤§å°: {download_result.get('actual_size', 0)} bytes")
                        else:
                            print(f"âŒ [TASK] å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_uuid} - {download_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            
                    except Exception as img_error:
                        print(f"âŒ [TASK] å¤„ç†å›¾ç‰‡ {img_info.get('uuid', 'unknown')} å¤±è´¥: {img_error}")
                        logger.warning(f"å¤„ç†å¯Œæ–‡æœ¬å›¾ç‰‡å¤±è´¥: {img_error}")
                        continue
                        
                print(f"ğŸ“Š [TASK] å¯Œæ–‡æœ¬è§£æå®Œæˆ: æˆåŠŸå¤„ç† {len(rich_text_images)} å¼ å›¾ç‰‡")
                execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: æˆåŠŸå¤„ç† {len(rich_text_images)} å¼ å›¾ç‰‡")
                        
            except json.JSONDecodeError as json_error:
                print(f"âŒ [TASK] å¯Œæ–‡æœ¬docå†…å®¹JSONè§£æå¤±è´¥: {json_error}")
                execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: JSONè§£æå¤±è´¥ - {json_error}")
                
        except Exception as parse_error:
            print(f"âŒ [TASK] å¯Œæ–‡æœ¬å›¾ç‰‡è§£æå¼‚å¸¸: {parse_error}")
            logger.error(f"å¯Œæ–‡æœ¬å›¾ç‰‡è§£æå¼‚å¸¸: {parse_error}")
            execution_log.append(f"å¯Œæ–‡æœ¬è§£æ: è§£æå¼‚å¸¸ - {parse_error}")

    async def _query_additional_fields(
        self,
        task: AnalysisTask,
        payload_data: Dict[str, Any],
        execution_log: list
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ä»»åŠ¡é…ç½®çš„é¢å¤–å­—æ®µ

        Args:
            task: åˆ†æä»»åŠ¡å¯¹è±¡
            payload_data: webhookåŸå§‹æ•°æ®
            execution_log: æ‰§è¡Œæ—¥å¿—åˆ—è¡¨

        Returns:
            å­—æ®µæ•°æ®å­—å…¸
        """
        try:
            # è§£æå¤šå­—æ®µé…ç½®
            multi_field_config = task.multi_field_config
            if not multi_field_config or 'fields' not in multi_field_config:
                return {}

            field_configs = multi_field_config['fields']
            if not field_configs:
                return {}

            # æå–webhookåŸºç¡€ä¿¡æ¯
            payload = payload_data.get('payload', {})
            project_key = payload.get('project_key')
            work_item_type_key = payload.get('work_item_type_key')
            work_item_id = str(payload.get('id', ''))

            if not all([project_key, work_item_type_key, work_item_id]):
                logger.warning("å¤šå­—æ®µæŸ¥è¯¢: ç¼ºå°‘å¿…è¦çš„é¡¹ç›®ä¿¡æ¯")
                return {}

            # è·å–é£ä¹¦APIé…ç½®
            import os
            plugin_id = os.getenv("FEISHU_PLUGIN_ID", "")
            plugin_secret = os.getenv("FEISHU_PLUGIN_SECRET", "")
            user_key = os.getenv("FEISHU_USER_KEY", "")

            if not all([plugin_id, plugin_secret]):
                logger.warning("å¤šå­—æ®µæŸ¥è¯¢: é£ä¹¦APIé…ç½®ç¼ºå¤±")
                return {}

            # ä½¿ç”¨é£ä¹¦æœåŠ¡æŸ¥è¯¢å¤šå­—æ®µ
            from app.services.feishu_service import FeishuProjectAPI

            feishu_api = FeishuProjectAPI(
                host="https://project.feishu.cn",
                app_id=plugin_id,
                app_secret=plugin_secret,
                user_id=user_key
            )

            # æå–è¦æŸ¥è¯¢çš„å­—æ®µåˆ—è¡¨
            field_keys = [field_config['field_key'] for field_config in field_configs]

            async with feishu_api:
                # è·å–plugin token
                plugin_token = await feishu_api.get_plugin_token(plugin_id, plugin_secret)

                # æŸ¥è¯¢å¤šå­—æ®µ
                query_result = await feishu_api.query_multiple_fields(
                    project_key=project_key,
                    work_item_type_key=work_item_type_key,
                    work_item_id=work_item_id,
                    field_keys=field_keys,
                    plugin_token=plugin_token,
                    user_key=user_key
                )

                if query_result.get('success'):
                    field_values = query_result.get('field_values', {})

                    # å°†field_keyæ˜ å°„ä¸ºplaceholderåç§°
                    placeholder_data = {}
                    for field_config in field_configs:
                        field_key = field_config['field_key']
                        placeholder = field_config['placeholder']

                        if field_key in field_values:
                            # å¤„ç†ä¸åŒç±»å‹çš„å­—æ®µå€¼
                            field_value = field_values[field_key]
                            if isinstance(field_value, dict):
                                # å¤æ‚å­—æ®µç±»å‹ï¼Œæå–æ–‡æœ¬å†…å®¹
                                if field_value.get('type') == 'rich_text':
                                    placeholder_data[placeholder] = field_value.get('doc_text', '')
                                elif field_value.get('type') == 'user':
                                    users = field_value.get('users', [])
                                    placeholder_data[placeholder] = ', '.join([user.get('name', '') for user in users])
                                elif field_value.get('type') == 'relation':
                                    relations = field_value.get('relations', [])
                                    placeholder_data[placeholder] = ', '.join([rel.get('name', '') for rel in relations])
                                else:
                                    placeholder_data[placeholder] = str(field_value)
                            else:
                                # ç®€å•å­—æ®µç±»å‹
                                placeholder_data[placeholder] = str(field_value) if field_value is not None else ''
                        else:
                            placeholder_data[placeholder] = ''

                    print(f"âœ… [TASK] å¤šå­—æ®µæŸ¥è¯¢æˆåŠŸ: {placeholder_data}")
                    return placeholder_data

                else:
                    logger.error(f"å¤šå­—æ®µæŸ¥è¯¢å¤±è´¥: {query_result}")
                    return {}

        except Exception as e:
            logger.error(f"å¤šå­—æ®µæŸ¥è¯¢å¼‚å¸¸: {e}")
            return {}

    def _extract_rich_text_content(self, field_value: Any) -> str:
        """
        ä»å¯Œæ–‡æœ¬å­—æ®µå€¼ä¸­æå–çº¯æ–‡æœ¬å†…å®¹

        Args:
            field_value: å¯Œæ–‡æœ¬å­—æ®µå€¼ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å¤æ‚å¯¹è±¡

        Returns:
            æå–çš„çº¯æ–‡æœ¬å†…å®¹
        """
        try:
            if not field_value:
                return ""

            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
            if isinstance(field_value, str):
                # å°è¯•è§£ææ˜¯å¦ä¸ºJSONæ ¼å¼çš„å¯Œæ–‡æœ¬
                try:
                    import json
                    rich_data = json.loads(field_value)
                    return self._extract_text_from_rich_json(rich_data)
                except:
                    # ä¸æ˜¯JSONï¼Œç›´æ¥è¿”å›å­—ç¬¦ä¸²
                    return field_value

            # å¦‚æœæ˜¯å­—å…¸å¯¹è±¡ï¼Œæå–æ–‡æœ¬å†…å®¹
            elif isinstance(field_value, dict):
                # æ£€æŸ¥æ˜¯å¦æœ‰docå­—æ®µï¼ˆå¯Œæ–‡æœ¬æ ¼å¼ï¼‰
                if 'doc' in field_value:
                    doc_content = field_value['doc']
                    if isinstance(doc_content, str):
                        try:
                            import json
                            doc_data = json.loads(doc_content)
                            return self._extract_text_from_rich_json(doc_data)
                        except:
                            return doc_content
                    elif isinstance(doc_content, dict):
                        return self._extract_text_from_rich_json(doc_content)

                # æ£€æŸ¥æ˜¯å¦æœ‰doc_textå­—æ®µï¼ˆçº¯æ–‡æœ¬æå–ï¼‰
                elif 'doc_text' in field_value:
                    return str(field_value['doc_text'])

                # å…¶ä»–æƒ…å†µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                else:
                    return str(field_value)

            # å…¶ä»–ç±»å‹ï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            else:
                return str(field_value)

        except Exception as e:
            logger.warning(f"å¯Œæ–‡æœ¬å†…å®¹æå–å¤±è´¥: {e}")
            return str(field_value) if field_value else ""

    def _extract_text_from_rich_json(self, rich_data: dict) -> str:
        """
        ä»å¯Œæ–‡æœ¬JSONç»“æ„ä¸­é€’å½’æå–çº¯æ–‡æœ¬å†…å®¹

        Args:
            rich_data: å¯Œæ–‡æœ¬JSONæ•°æ®

        Returns:
            æå–çš„çº¯æ–‡æœ¬
        """
        try:
            text_parts = []

            def extract_from_ops(ops_data):
                if isinstance(ops_data, dict):
                    # æ£€æŸ¥æ˜¯å¦æœ‰insertå­—æ®µï¼ˆæ–‡æœ¬å†…å®¹ï¼‰
                    if 'insert' in ops_data and isinstance(ops_data['insert'], str):
                        # è·³è¿‡å›¾ç‰‡ç­‰éæ–‡æœ¬å†…å®¹
                        attributes = ops_data.get('attributes', {})
                        if not attributes.get('image'):  # ä¸æ˜¯å›¾ç‰‡
                            text_parts.append(ops_data['insert'])

                    # é€’å½’å¤„ç†å­å¯¹è±¡
                    for value in ops_data.values():
                        if isinstance(value, (dict, list)):
                            extract_from_ops(value)

                elif isinstance(ops_data, list):
                    for item in ops_data:
                        extract_from_ops(item)

            # æ£€æŸ¥opså­—æ®µï¼ˆDeltaæ ¼å¼ï¼‰
            if 'ops' in rich_data:
                extract_from_ops(rich_data['ops'])
            else:
                # ç›´æ¥å¤„ç†æ•´ä¸ªæ•°æ®
                extract_from_ops(rich_data)

            # åˆå¹¶æ–‡æœ¬å¹¶æ¸…ç†
            result = ''.join(text_parts).strip()
            # æ¸…ç†å¤šä½™çš„æ¢è¡Œç¬¦
            import re
            result = re.sub(r'\n\s*\n', '\n', result)

            return result

        except Exception as e:
            logger.warning(f"å¯Œæ–‡æœ¬JSONè§£æå¤±è´¥: {e}")
            return ""

    def _render_template_with_fields(self, template: str, field_data: Dict[str, Any]) -> str:
        """
        ä½¿ç”¨å­—æ®µæ•°æ®æ¸²æŸ“æç¤ºè¯æ¨¡æ¿

        Args:
            template: æç¤ºè¯æ¨¡æ¿ï¼ŒåŒ…å« {å­—æ®µå ä½ç¬¦} æ ¼å¼çš„å ä½ç¬¦
            field_data: å­—æ®µæ•°æ®å­—å…¸ï¼Œé”®ä¸ºå ä½ç¬¦åç§°ï¼Œå€¼ä¸ºå­—æ®µå€¼

        Returns:
            æ¸²æŸ“åçš„æç¤ºè¯
        """
        try:
            import re

            rendered_template = template

            # å¤„ç†å­—æ®µå ä½ç¬¦ {placeholder_name}
            for placeholder, value in field_data.items():
                # è½¬æ¢ä¸ºå®‰å…¨çš„å­—ç¬¦ä¸²
                safe_value = str(value) if value is not None else ''
                # æ›¿æ¢å ä½ç¬¦
                rendered_template = rendered_template.replace(f'{{{placeholder}}}', safe_value)

            # æ¸…ç†æœªåŒ¹é…çš„å ä½ç¬¦ï¼ˆå¯é€‰ï¼‰
            # rendered_template = re.sub(r'\{[^}]+\}', '[æœªæ‰¾åˆ°å­—æ®µ]', rendered_template)

            return rendered_template

        except Exception as e:
            logger.error(f"æ¨¡æ¿æ¸²æŸ“å¤±è´¥: {e}")
            return template

    async def _validate_webhook_execution(
        self,
        payload_data: Dict[str, Any],
        analysis_tasks: list,
        execution_id: str,
        execution_log: list
    ) -> Dict[str, Any]:
        """
        éªŒè¯Webhookæ˜¯å¦åº”è¯¥æ‰§è¡Œä»»åŠ¡ï¼Œé˜²æ­¢é‡å¤æ‰§è¡Œ

        Args:
            payload_data: Webhookè½½è·æ•°æ®
            analysis_tasks: è¦æ‰§è¡Œçš„åˆ†æä»»åŠ¡åˆ—è¡¨
            execution_id: å½“å‰æ‰§è¡ŒID
            execution_log: æ‰§è¡Œæ—¥å¿—åˆ—è¡¨

        Returns:
            éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å« should_execute, skip_reason, details
        """
        try:
            print(f"ğŸ” [VALIDATION] å¼€å§‹æ‰§è¡Œé¢„æ£€æŸ¥éªŒè¯...")

            # ä»payloadä¸­æå–å…³é”®æ•°æ®
            record_id = None
            field_value = None
            if isinstance(payload_data, dict) and "payload" in payload_data:
                inner_payload = payload_data["payload"]
                if isinstance(inner_payload, dict):
                    record_id = inner_payload.get("id")
                    changed_fields = inner_payload.get("changed_fields", [])
                    if isinstance(changed_fields, list) and len(changed_fields) > 0:
                        field_value = changed_fields[0].get("cur_field_value")

            print(f"ğŸ“Š [VALIDATION] æå–æ•°æ®: record_id={record_id}, field_value={'å·²è·å–' if field_value else 'æœªè·å–'}")

            # éªŒè¯1: å¯Œæ–‡æœ¬è§£ææ£€æŸ¥
            for task in analysis_tasks:
                if task.enable_rich_text_parsing:
                    print(f"ğŸ–¼ï¸ [VALIDATION] æ£€æŸ¥ä»»åŠ¡ {task.name} çš„å¯Œæ–‡æœ¬è§£æé…ç½®...")

                    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å¯Œæ–‡æœ¬å†…å®¹
                    if not field_value:
                        skip_reason = f"å¯Œæ–‡æœ¬è§£æå·²å¯ç”¨ä½†å­—æ®µå€¼ä¸ºç©º (ä»»åŠ¡: {task.name})"
                        print(f"âš ï¸ [VALIDATION] {skip_reason}")
                        execution_log.append(f"éªŒè¯å¤±è´¥: {skip_reason}")

                        return {
                            "should_execute": False,
                            "skip_reason": skip_reason,
                            "details": {
                                "validation_type": "rich_text_empty",
                                "task_id": task.id,
                                "task_name": task.name,
                                "record_id": record_id,
                                "field_value_present": False
                            }
                        }

                    # æ£€æŸ¥å¯Œæ–‡æœ¬å†…å®¹ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡
                    has_images = await self._check_rich_text_has_images(field_value, task, payload_data)
                    print(f"ğŸ” [VALIDATION] å¯Œæ–‡æœ¬å›¾ç‰‡æ£€æŸ¥ç»“æœ: has_images={has_images}")

                    if not has_images:
                        skip_reason = f"å¯Œæ–‡æœ¬è§£æå·²å¯ç”¨ä½†å†…å®¹ä¸­æ— å›¾ç‰‡ (ä»»åŠ¡: {task.name})"
                        print(f"âš ï¸ [VALIDATION] {skip_reason}")
                        execution_log.append(f"éªŒè¯å¤±è´¥: {skip_reason}")

                        return {
                            "should_execute": False,
                            "skip_reason": skip_reason,
                            "details": {
                                "validation_type": "rich_text_no_images",
                                "task_id": task.id,
                                "task_name": task.name,
                                "record_id": record_id,
                                "field_value_present": True,
                                "images_found": False
                            }
                        }

            # éªŒè¯2: é‡å¤æ‰§è¡Œæ£€æŸ¥
            if record_id:
                print(f"ğŸ”„ [VALIDATION] æ£€æŸ¥record_id={record_id}çš„é‡å¤æ‰§è¡Œæƒ…å†µ...")

                # æŸ¥è¯¢æ˜¯å¦æœ‰ç›¸åŒrecord_idçš„ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­
                from app.models.task_execution_simple import TaskExecution, ExecutionStatus
                from sqlalchemy import and_

                # æ£€æŸ¥æ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ä¸­æ˜¯å¦æœ‰ç›¸åŒçš„record_id
                running_executions = self.db.query(TaskExecution).filter(
                    and_(
                        TaskExecution.execution_status.in_([ExecutionStatus.PENDING, ExecutionStatus.PROCESSING]),
                        TaskExecution.webhook_payload.is_not(None)
                    )
                ).all()

                conflicting_executions = []
                for exec_record in running_executions:
                    if exec_record.webhook_payload and isinstance(exec_record.webhook_payload, dict):
                        exec_payload = exec_record.webhook_payload.get("payload", {})
                        if isinstance(exec_payload, dict) and exec_payload.get("id") == record_id:
                            # æ’é™¤å½“å‰æ‰§è¡Œ
                            if exec_record.execution_id != execution_id:
                                conflicting_executions.append(exec_record)

                print(f"ğŸ“Š [VALIDATION] å‘ç° {len(conflicting_executions)} ä¸ªå†²çªçš„æ‰§è¡Œè®°å½•")

                if conflicting_executions:
                    conflict_info = []
                    for conflict in conflicting_executions:
                        conflict_info.append({
                            "execution_id": conflict.execution_id,
                            "task_id": conflict.task_id,
                            "status": conflict.execution_status.value,
                            "started_at": conflict.started_at.isoformat() if conflict.started_at else None
                        })

                    skip_reason = f"æ£€æµ‹åˆ°record_id={record_id}çš„ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œé¿å…é‡å¤å¤„ç†"
                    print(f"âš ï¸ [VALIDATION] {skip_reason}")
                    execution_log.append(f"éªŒè¯å¤±è´¥: {skip_reason}")

                    return {
                        "should_execute": False,
                        "skip_reason": skip_reason,
                        "details": {
                            "validation_type": "duplicate_execution",
                            "record_id": record_id,
                            "conflicting_executions": conflict_info,
                            "conflict_count": len(conflicting_executions)
                        }
                    }

            # æ‰€æœ‰éªŒè¯é€šè¿‡
            print(f"âœ… [VALIDATION] é¢„æ£€æŸ¥éªŒè¯é€šè¿‡ï¼Œå¯ä»¥æ‰§è¡Œä»»åŠ¡")
            execution_log.append("é¢„æ£€æŸ¥éªŒè¯: é€šè¿‡")

            return {
                "should_execute": True,
                "skip_reason": None,
                "details": {
                    "validation_type": "passed",
                    "record_id": record_id,
                    "rich_text_tasks_count": sum(1 for task in analysis_tasks if task.enable_rich_text_parsing),
                    "all_validations_passed": True
                }
            }

        except Exception as e:
            error_msg = f"é¢„æ£€æŸ¥éªŒè¯å¼‚å¸¸: {str(e)}"
            print(f"âŒ [VALIDATION] {error_msg}")
            logger.error(error_msg, exc_info=True)
            execution_log.append(error_msg)

            # éªŒè¯å¼‚å¸¸æ—¶å…è®¸æ‰§è¡Œï¼Œé¿å…é˜»å¡æ­£å¸¸æµç¨‹
            return {
                "should_execute": True,
                "skip_reason": None,
                "details": {
                    "validation_type": "error",
                    "error": error_msg
                }
            }

    async def _check_rich_text_has_images(
        self,
        field_value: Any,
        task: AnalysisTask,
        payload_data: Dict[str, Any]
    ) -> bool:
        """
        æ£€æŸ¥å¯Œæ–‡æœ¬å­—æ®µå€¼ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡

        Args:
            field_value: å¯Œæ–‡æœ¬å­—æ®µå€¼
            task: åˆ†æä»»åŠ¡å¯¹è±¡
            payload_data: å®Œæ•´çš„webhookè½½è·æ•°æ®

        Returns:
            bool: æ˜¯å¦åŒ…å«å›¾ç‰‡
        """
        try:
            if not field_value:
                return False

            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
            if isinstance(field_value, str):
                try:
                    import json
                    field_data = json.loads(field_value)
                except json.JSONDecodeError:
                    # ä¸æ˜¯JSONæ ¼å¼ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡ç›¸å…³çš„æ–‡æœ¬æ ‡è¯†
                    return any(keyword in field_value.lower() for keyword in ['image', 'img', 'å›¾ç‰‡', 'å›¾åƒ'])
            else:
                field_data = field_value

            # æ£€æŸ¥å¯Œæ–‡æœ¬ç»“æ„ä¸­çš„å›¾ç‰‡ä¿¡æ¯
            if isinstance(field_data, dict):
                # æ£€æŸ¥docå­—æ®µï¼ˆå¯Œæ–‡æœ¬æ ¼å¼ï¼‰
                if 'doc' in field_data:
                    doc_content = field_data['doc']
                    if isinstance(doc_content, str):
                        try:
                            import json
                            doc_data = json.loads(doc_content)
                        except json.JSONDecodeError:
                            return False
                    else:
                        doc_data = doc_content

                    # é€’å½’æœç´¢opsä¸­çš„imageå±æ€§
                    if isinstance(doc_data, dict) and 'ops' in doc_data:
                        return self._search_images_in_ops(doc_data['ops'])

            return False

        except Exception as e:
            logger.warning(f"æ£€æŸ¥å¯Œæ–‡æœ¬å›¾ç‰‡æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            # å¼‚å¸¸æ—¶è¿”å›Trueï¼Œé¿å…è¯¯åˆ¤
            return True

    def _search_images_in_ops(self, ops_data) -> bool:
        """
        åœ¨opsæ•°æ®ç»“æ„ä¸­é€’å½’æœç´¢å›¾ç‰‡

        Args:
            ops_data: opsæ•°æ®ç»“æ„

        Returns:
            bool: æ˜¯å¦æ‰¾åˆ°å›¾ç‰‡
        """
        try:
            if isinstance(ops_data, dict):
                # æ£€æŸ¥æ˜¯å¦æœ‰imageå±æ€§
                if ops_data.get('attributes', {}).get('image') == 'true':
                    return True

                # é€’å½’æ£€æŸ¥å­å¯¹è±¡
                for value in ops_data.values():
                    if isinstance(value, (dict, list)):
                        if self._search_images_in_ops(value):
                            return True

            elif isinstance(ops_data, list):
                for item in ops_data:
                    if self._search_images_in_ops(item):
                        return True

            return False

        except Exception as e:
            logger.warning(f"æœç´¢opsä¸­çš„å›¾ç‰‡æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            return True  # å¼‚å¸¸æ—¶è¿”å›Trueï¼Œé¿å…è¯¯åˆ¤


# å…¨å±€ä»»åŠ¡å¤„ç†å‡½æ•°ï¼ˆä¾›FastAPI BackgroundTasksä½¿ç”¨ï¼‰
async def process_webhook_async(
    webhook_id: int,
    payload_data: Dict[str, Any],
    execution_id: str,
    client_ip: str,
    user_agent: str
) -> Dict[str, Any]:
    """
    å¼‚æ­¥å¤„ç†Webhookä»»åŠ¡
    è¿™æ˜¯è¢«FastAPI BackgroundTasksè°ƒç”¨çš„å…¥å£å‡½æ•°
    """
    print(f"\nğŸš€ [DEBUG] å¼€å§‹å¼‚æ­¥å¤„ç†Webhookä»»åŠ¡")
    print(f"   - Webhook ID: {webhook_id}")
    print(f"   - æ‰§è¡ŒID: {execution_id}")
    print(f"   - å®¢æˆ·ç«¯IP: {client_ip}")
    print(f"   - Payloadå¤§å°: {len(str(payload_data))} å­—ç¬¦")
    
    try:
        with WebhookTaskProcessor() as processor:
            print(f"âœ… [DEBUG] WebhookTaskProcessor åˆ›å»ºæˆåŠŸ")
            
            result = await processor.process_webhook_task(
                webhook_id=webhook_id,
                payload_data=payload_data,
                execution_id=execution_id,
                client_ip=client_ip,
                user_agent=user_agent
            )
            
            print(f"ğŸ‰ [DEBUG] å¼‚æ­¥ä»»åŠ¡å¤„ç†å®Œæˆ {execution_id}: æˆåŠŸ={result['success']}")
            logger.info(f"å¼‚æ­¥ä»»åŠ¡å¤„ç†å®Œæˆ {execution_id}: {result['success']}")
            return result
            
    except Exception as e:
        print(f"âŒ [DEBUG] å¼‚æ­¥ä»»åŠ¡å¤„ç†å¼‚å¸¸ {execution_id}: {e}")
        print(f"   - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        import traceback
        print(f"   - å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        
        logger.error(f"å¼‚æ­¥ä»»åŠ¡å¤„ç†å¼‚å¸¸ {execution_id}: {e}", exc_info=True)
        
        return {
            "success": False,
            "execution_id": execution_id,
            "webhook_id": webhook_id,
            "error": str(e),
            "error_type": type(e).__name__,
            "timestamp": datetime.utcnow().isoformat()
        }